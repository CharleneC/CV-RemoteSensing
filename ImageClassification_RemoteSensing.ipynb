{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro To Image Classification using Remote Sensing Data   \n",
    "\n",
    "This notebook will take you through an image classification example using models and data from the torch library. The written code covers the main components of a machine learning experiment (data preparation, model definition, evaluation scripts, etc), with tasks/questions embedded throughout to aid the user in understanding the results.    \n",
    "\n",
    "To use the GPU in Google Colab: Runtime > Change Runtime type , then select \"Python 3\" and \"T4 GPU\"\n",
    "\n",
    "If you would like to learn more about the dataset, check out the paper: https://arxiv.org/pdf/1709.00029.pdf    \n",
    "Tutorial adapted from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm #for-loop progress bar\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ssl \n",
    "ssl._create_default_https_context = ssl._create_unverified_context #to download torch dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define variables\n",
    "Here we need to define where our data will be saved, batch_size (i.e. how many samples we load at once), as well dataset sizes for the training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '.' #use current directory\n",
    "batch_size = 4\n",
    "train_size = .8\n",
    "test_size = .2\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download Dataset to Root Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transformations that each sample will undergo as it's loaded\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = torchvision.datasets.EuroSAT(root = root_folder, download=True, transform = transform) #takes about ~1min to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#generate a training/testing data split\n",
    "generator = torch.Generator().manual_seed(40) #to reproduce results\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size],generator=generator)\n",
    "\n",
    "\n",
    "#create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "                                         \n",
    "print('There are ' + str(len(train_dataset)) + ' training images')\n",
    "print('There are ' + str(len(test_dataset)) + ' test images')\n",
    "print('There are ' + str(  len(dataset.classes) ) + ' classes')\n",
    "class_to_idx = dict(zip(range(len(dataset.classes)),dataset.classes))\n",
    "\n",
    "print(class_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect one batch of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(' '.join(f'{class_to_idx[int(labels[j])]:5s}' for j in range(batch_size)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: What's the Height/Width of one image?\n",
    "Hint: `images` is a torch.Tensor that has a `shape` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Insert code here. \n",
    "\n",
    "\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: How many samples do we have per class?\n",
    "Hint: checkout `dataset.samples`. Converting it to a numpy array may be useful too using `np.array(dataset.samples)`\n",
    "\n",
    "### Extra: what do you think happens if we have over-represented classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Insert code here\n",
    "\n",
    "\n",
    "# all_labels = ??\n",
    "# '''\n",
    "plt.hist(all_labels, bins=list(range(11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our Nueral Network Model\n",
    "This is the fun part! Here, we define a simple convolutional nueral network that outputs the class probabilities for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = torch.nn.Linear(2704, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10) # the 10 here represents how many classes we are predicting\n",
    "        # the outputs will look like [prob_class_0, prob_class_2,...,prob_class_9]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Model\n",
    "Run 2 epochs (i.e. passes through the dataset) to train the model\n",
    "\n",
    "#### Extra: Plot the loss per epoch\n",
    "Adapt the training script to collect the running loss at the end of each epoch and use `plt.plot(x,y)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times. For the simple model, ~1 epoch takes about 15 seconds. For resnet, 1 epoch takes about ~2.5min\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 200 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the trained model on the test set\n",
    "Here, we iterate through the test set and collect the amount of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: Go back and run the training cell again for two more epochs. How much does your model's accuracy improve?\n",
    "\n",
    "### EXTRA: replace your simple net with a pre-trained model from the torchvision library:\n",
    "```\n",
    "#load a neural network\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "#pretrained resnet outputs 1000 classes. Here we change that to the 10 we have in our dataset\n",
    "resnet.fc.out_features=10\n",
    "resnet.to(device)\n",
    "```\n",
    "Train this new model. How does classifation accuracy compare with the simple model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: Plot a Confusion Matrix to visualize how the model performed for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: First, we need to collect lists of ALL the truth labels and predictions from the test dataset.    \n",
    "Adapt the evaluation code block to collect truth labels and predictions for the entire test set    \n",
    "Look at the 'predicted' and 'labels' variables. 'predicted' and 'labels are both type torch.Tensor, torch.Tensor.tolist() may be useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Insert code here\n",
    "\n",
    "#  preds = ?? \n",
    "#  truth = ??\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(truth, preds, labels=list(range(10)))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=list(range(10)))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python (amn)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
